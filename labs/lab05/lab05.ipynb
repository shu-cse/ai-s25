{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333722a4",
   "metadata": {},
   "source": [
    "# Lab 05: Linear Regression\n",
    "In Lab 05, we will write a simple gradient descent algorithm to learn weights for housing price prediction. We will only use one variable (area), but we will train over a whole dataset. \n",
    "\n",
    "By the end of this lab, you should be know very clearly how Gradient Descent works for single variable linear regression.\n",
    "\n",
    "**SUBMISSION**\n",
    "\n",
    "You should submit a `lab05-yourname.py` file on Moodle, NOT a Jupyter Notebook, which answers the EXERCISE QUESTIONS (using comments) and which solves the ASSIGNMENT below. PLEASE DO NOT USE ARABIC IN THE FILENAME.\n",
    "\n",
    "**LAB CLASS SOLUTIONS**\n",
    "\n",
    "You may use the code that is covered in class time, but you _must_ (re-)type it yourself!!  So, during lab class, I recommend that you open a `lab05-yourname.py` file in VSCode and try to run bits of it as we go along.\n",
    "\n",
    "**DUE DATE**\n",
    "\n",
    "30th April, 2025 -- 1 week\n",
    "\n",
    "**GRADING**\n",
    "\n",
    "This Lab is worth 12.5% of your overall course grade. Completeness, correct output/answers, and style are all part of the criteria.\n",
    "\n",
    "**LATE WORK**\n",
    "\n",
    "Late work will be penalized by 25 points. However, it can be submitted until the day of the Final Exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80f91a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "from random import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5984124d",
   "metadata": {},
   "source": [
    "## Walkthrough: Import Data from Kaggle\n",
    "We take our data from the [Housing Prices Dataset on Kaggle](https://www.kaggle.com/datasets/yasserh/housing-prices-dataset/data). This gives the `price` of houses based on numeric features like `area` or `bedrooms`, but also categorical features like `basement` and `airconditioning`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf02888",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"yasserh/housing-prices-dataset\")\n",
    "df = pd.read_csv(path + \"/Housing.csv\")\n",
    "print(f\"Imported housing prices dataset with {df.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e7909d",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prices = pd.DataFrame()\n",
    "housing_prices['price_1M'] = df['price'].apply(lambda x:x/1000000)\n",
    "housing_prices['area_100m'] = df['area'].apply(lambda x:x/1000)\n",
    "housing_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eabd6c",
   "metadata": {},
   "source": [
    "### Exercise questions\n",
    "**Q1**: What did we just do with the data in the code above? (Mark with an X instead of line)\n",
    "```\n",
    "    _ Regularize\n",
    "    _ Normalize\n",
    "    _ Calculate the gradient\n",
    "    _ Determine the error\n",
    "```\n",
    "\n",
    "**Q2**: What kind of problem can we use the `housing_prices` variable to solve?\n",
    "```\n",
    "    _ Estimating a 'price' (numeric) based on 'area' (numeric)\n",
    "    _ Estimating a 'price' (numeric) based on many variables\n",
    "    _ Estimating the 'area' (numeric) based on many variables\n",
    "    _ Classifying whether houses are desirable, based on 'price' and 'area'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4091e8",
   "metadata": {},
   "source": [
    "## Walkthrough: Set random weights (set up for gradient descent)\n",
    "In linear regression (and with lots of supervised learning techniques), we:\n",
    "\n",
    "* Choose some random weights/parameters to start\n",
    "* Calculate the gradient \n",
    "* Update the weights\n",
    "\n",
    "We will do this with Gradient Descent using the Mean Squared Error (MSE) loss function (also known as L2 loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b75c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [random()-0.5 for i in range(2)]\n",
    "init_weights = weights.copy()\n",
    "print(f\"Initial weights: {weights}\")\n",
    "\n",
    "plt.scatter(housing_prices['area_100m'],\n",
    "            housing_prices['price_1M'])\n",
    "x_line = np.linspace(housing_prices['area_100m'].min(),\n",
    "                     housing_prices['area_100m'].max(), 100)\n",
    "y_init = init_weights[1] * x_line + init_weights[0]\n",
    "plt.plot(x_line, y_init, color='red', label=\"Original Weights\")\n",
    "plt.xlabel(\"Area (100mÂ²)\")\n",
    "plt.ylabel(\"Price (1M$)\")\n",
    "plt.title(\"Housing Prices with regression of randomized initial weights\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80866252",
   "metadata": {},
   "source": [
    "### Exercise questions\n",
    "**Q3**: What does the plot above show us?\n",
    "```\n",
    "    _ Categorical variables can be plotted as different points on a scatterplot\n",
    "    _ Randomized starting points need only minor tweaking\n",
    "    _ Prices tend to be higher for bigger houses\n",
    "    _ A poorly fit red line means that the linear hypothesis space is inappropriate for this data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d91758",
   "metadata": {},
   "source": [
    "## Assignment (REQUIRED): Implement the gradient descent updates\n",
    "In the previous section, we have just defined a weight $w_1$ (`weights[1]`) and a bias term $w_0$ (`weights[0]`). Your goal now is to update those weights by comparing your estimates to the output. Essentially, we are writing an equation in a format like $y=mx+b$. Let's call the `price_1M` our $y$ and the `area_100m` our $x$. When we want to make a prediction, we put a \"hat\" on it, so _predicted_ price is written $\\hat{y}$. \n",
    "\n",
    "**Step 1**: Calculate the predicted price\n",
    "$$\n",
    "\\hat{y}=w_1 x + w_0\n",
    "$$\n",
    "\n",
    "**Step 2**: Calculate the average gradients. In class we saw equations that were like this: $\\frac{\\delta L}{\\delta w_0} = 2(\\hat{y}-y)$ and $\\frac{\\delta L}{\\delta w_1} = 2(\\hat{y}-y)\\cdot x$.\n",
    "\n",
    "Here, though, we have many values of $x$ (we can say it is \"vector-valued\" and write it as $\\mathbf{x}$), but we want to calculate just one weight update for all of them. So average the values above across the $x$ samples. \n",
    "$$\n",
    "\\frac{\\delta L}{\\delta w_0} = \\frac{1}{n}\\sum_{x\\in\\mathbf{x}} 2(\\hat{y}-y)\\\\\n",
    "\\frac{\\delta L}{\\delta w_1} = \\frac{1}{n}\\sum_{x\\in\\mathbf{x}} 2(\\hat{y}-y)\\cdot x\n",
    "$$\n",
    "\n",
    "**Step 3**: Calculate the updated weights. We mark updated values with a \"prime\" ($w^\\prime$ instead of $w$). Just remember that we will include a learning parameter, which you should set to $\\eta=0.01$ for this Lab.\n",
    "$$\n",
    "w_0^\\prime = w_0 - \\eta \\frac{\\delta L}{\\delta w_0}\\\\\n",
    "w_1^\\prime = w_1 - \\eta \\frac{\\delta L}{\\delta w_1}\n",
    "$$\n",
    "\n",
    "Then, repeat everything 1000 times (i.e., 1000 epochs).\n",
    "\n",
    "Your task is to put this into code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec976040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learning rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "## YOUR CODE HERE ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88af69f3",
   "metadata": {},
   "source": [
    "## Extra: Plot the updated regression line and the training curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b1e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f069957c",
   "metadata": {},
   "source": [
    "To get a plot of the loss, you need to have tracked the loss over each epoch. Go back and add code that calculates the mean squared error into your loop, at the end of each epoch. Here's `aima-python`'s implementation of the mean squared error calculation:\n",
    "```\n",
    "def mean_squared_error_loss(x, y):\n",
    "    return (1.0 / len(x)) * sum((_x - _y) ** 2 for _x, _y in zip(x, y))\n",
    "```\n",
    "\n",
    "Then, once you've kept a list of the loss values at each epoch, plot them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f78efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
