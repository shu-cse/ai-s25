{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e38ce7b",
   "metadata": {},
   "source": [
    "# Lab 07: Evaluation Loops\n",
    "In lecture, we looked at how to evaluate machine learning algorithms. \n",
    "\n",
    "In this lab, we'll:\n",
    "- Build on last week's Iris data set manipulation and SimpleNeuralNetwork\n",
    "- Write the code for evaluating the neural network\n",
    "\n",
    "The goal is to understand clearly what are evaluations are doing, in code.\n",
    "\n",
    "If you haven't done it yet, `pip install scikit-learn` in order to have access to the `sklearn` library\n",
    "\n",
    "**SUBMISSION**\n",
    "\n",
    "You should submit a `lab07-yourname.py` file on Moodle, NOT a Jupyter Notebook. PLEASE DO NOT USE ARABIC IN THE FILENAME.\n",
    "\n",
    "**LAB CLASS SOLUTIONS**\n",
    "\n",
    "You may use the code that is covered in class time, but you _must_ (re-)type it yourself!!  So, during lab class, I recommend that you open a `lab07-yourname.py` file in VSCode and try to run bits of it as we go along.\n",
    "\n",
    "**DUE DATE**\n",
    "\n",
    "14th May, 2025 -- 1 week\n",
    "\n",
    "**GRADING**\n",
    "\n",
    "This Lab is worth 12.5% of your overall course grade. Completeness, correct output/answers, and style are all part of the criteria. There is an optional extra credit portion that is challenging, and can be worth an extra 50% on this assignment.\n",
    "\n",
    "**LATE WORK**\n",
    "\n",
    "Late work will be penalized by 25 points. However, it can be submitted until the day of the Final Exam.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19413975",
   "metadata": {},
   "source": [
    "# Importing data and SimpleNeuralNetwork\n",
    "We'll start with essentially what we did last time. Here's the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6a583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from neuralnetworks import *\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Index of flower species to remove\n",
    "idx_remove_species = y < 2\n",
    "\n",
    "# # Limit to 2 flower species\n",
    "y = y[idx_remove_species]\n",
    "X = X[idx_remove_species]\n",
    "\n",
    "# Limit to 2 features\n",
    "X = X[:, [0, 2]]\n",
    "print(f\"Input has shape {X.shape}\")\n",
    "print(f\"Output has shape {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff50666",
   "metadata": {},
   "source": [
    "## EXERCISE: Shuffle and split the data\n",
    "Write a function that randomly splits the data `X` and `y`, with 80% going into a train set and 20% going into a test set. \n",
    "\n",
    "**Hint 1**: Instead of directly splitting the data, pick indices to be in one group or the other. This way, you can split both `X` and `y` the same way.\n",
    "\n",
    "**Hint 2**: Use `np.shuffle()` for the randomization of indices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb1abe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccff9136",
   "metadata": {},
   "source": [
    "Now let's visualize that data. We'll plot the 2 remaining X (feature) values on a scatter plot and show what class they are part of with color.\n",
    "\n",
    "Also, we'll define a SimpleNeuralNetwork with random guessed weights, and see what kind of surface it defines. We've implemented a `plot_decision_surface()` method in `SimpleNeuralNetwork` that is called with `X` and `y`. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f909548",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = SimpleNeuralNetwork(2, 3)\n",
    "# nn.plot_decision_surface(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ce5e08",
   "metadata": {},
   "source": [
    "## EXERCISE (UNGRADED): Train the network, one epoch at a time\n",
    "We have `forward` and `backward` methods in our `SimpleNeuralNetwork`, appropriate for updating the weights for one training epoch. \n",
    "\n",
    "* Write a simple for loop that calls these `forward` and `backward` 1000 times. Use 0.03 for your `learning_rate`.\n",
    "* After you're done, visualize the decision surface again with `nn.plot_decision_surface()`. \n",
    "\n",
    "THIS PORTION DOES NOT NEED TO BE TURNED IN, SINCE WE WILL MODIFY/UPDATE IT LATER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8dea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE -- UNGRADED\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9345d34f",
   "metadata": {},
   "source": [
    "## EXERCISE: Get performance on the dev set\n",
    "It's great that we can learn weights and biases via the backprop algorithm (what we just did by calling `forward` and `backward`)! But instead of just looking at the plot, let's try to characterize our performance.\n",
    "\n",
    "* Split the data again so you have 80% `train` + 10% `dev` + 10% `other`.\n",
    "* Train your epochs again on the `train` set only.\n",
    "* Run `predict` on your `dev` data, then compare with the gold standard.\n",
    "* Compare the `predict`ions with the gold standard to calculate an accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950cc67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9a21d5",
   "metadata": {},
   "source": [
    "## EXTRA CREDIT\n",
    "There are many other things that could be done with this data and setup. Do any of the following to get 50 points of extra credit on the lab:\n",
    "\n",
    "* Track the train/dev set loss, and test for convergence (when the loss stops changing much). What criteria did you find could work programmatically for convergence?\n",
    "* Use more difficult data, for example, the harder-to-separate classes `1` and `2` (versicolor and virginica), and ensure the learner can separate these. What hyperparameter changes do you need to make to distinguish between them? Show a record of the different hyperparameters you tried.\n",
    "* Change the underlying `neuralnetworks` module to accommodate 3 classes. This requires replacing the `sigmoid` activation at the output with `softmax`, and choosing the top probability (i.e., `argmax`) in the output layer.\n",
    "\n",
    "These are hard! Good luck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cefd53d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
