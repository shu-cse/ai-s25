{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "946d8431",
      "metadata": {
        "id": "946d8431",
        "papermill": {
          "duration": 0.011395,
          "end_time": "2023-11-14T08:40:08.983629",
          "exception": false,
          "start_time": "2023-11-14T08:40:08.972234",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Lab 02 (remixed): Training and Evaluating a Decision Tree\n",
        "\n",
        "Answer the exercise questions.\n",
        "\n",
        "**Objectives**: After completing these exercises, you should be able to:\n",
        "\n",
        "* Identify the components of an ML annotation project\n",
        "* Clean some data\n",
        "* Code a decision tree\n",
        "\n",
        "Written by: Dr. Stephen Wu\n",
        "\n",
        "References: [Titanic on Kaggle](https://www.kaggle.com/competitions/titanic)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3d0c90a",
      "metadata": {
        "id": "b3d0c90a",
        "papermill": {
          "duration": 0.011496,
          "end_time": "2023-11-14T08:40:12.176161",
          "exception": false,
          "start_time": "2023-11-14T08:40:12.164665",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Setting up the environment and Titanic data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "421f8034",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-11-14T08:40:09.008601Z",
          "iopub.status.busy": "2023-11-14T08:40:09.007665Z",
          "iopub.status.idle": "2023-11-14T08:40:12.127558Z",
          "shell.execute_reply": "2023-11-14T08:40:12.126571Z"
        },
        "id": "421f8034",
        "papermill": {
          "duration": 3.135484,
          "end_time": "2023-11-14T08:40:12.130323",
          "exception": false,
          "start_time": "2023-11-14T08:40:08.994839",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.1.1; however, version 25.0.1 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\bahas\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\users\\bahas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.6.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\bahas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\bahas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\bahas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\bahas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Install scikit-learn if not already installed, and run\n",
        "%pip install scikit-learn\n",
        "import sklearn # machine learning algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6a6f144",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "execution": {
          "iopub.execute_input": "2023-11-14T08:40:12.201141Z",
          "iopub.status.busy": "2023-11-14T08:40:12.200185Z",
          "iopub.status.idle": "2023-11-14T08:40:12.257442Z",
          "shell.execute_reply": "2023-11-14T08:40:12.256161Z"
        },
        "id": "c6a6f144",
        "outputId": "b044f895-4965-4fd5-eef7-9adfbe6b50a4",
        "papermill": {
          "duration": 0.072628,
          "end_time": "2023-11-14T08:40:12.260115",
          "exception": false,
          "start_time": "2023-11-14T08:40:12.187487",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The first dataset has 891 samples while the second dataset has 418; a \n",
            "68.07/31.93 split of the data.\n"
          ]
        }
      ],
      "source": [
        "# Get the Titanic data (originally from Kaggle)\n",
        "dl_train_url = \"../lab01/train.csv\"\n",
        "dl_test_url = \"../lab01/test.csv\"\n",
        "\n",
        "train_data = pd.read_csv(dl_train_url)\n",
        "test_data = pd.read_csv(dl_test_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82fafdd7",
      "metadata": {
        "id": "82fafdd7",
        "papermill": {
          "duration": 0.013759,
          "end_time": "2023-11-14T08:40:13.334097",
          "exception": false,
          "start_time": "2023-11-14T08:40:13.320338",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Exercise 2.1: Problem setup (GRADED)\n",
        "Mark the correct answer with an `X`.\n",
        "\n",
        "1. Eventually, we want to _predict_ whether people `Survived` or not. What kind of an ML problem will this be?\n",
        "\n",
        "```\n",
        "    a) Clustering\n",
        "    b) Classification\n",
        "    c) Regression\n",
        "    d) Generation\n",
        "```\n",
        "\n",
        "2. What's the difference between `train_data` and `test_data`? '\n",
        "\n",
        "```\n",
        "    a) `test_data` has extra variables that `train_data` doesn't\n",
        "    b) `test_data` lacks the output variable\n",
        "    c) `test_data` is used first to help the algorithm find patterns on real data\n",
        "    d) `train_data` is \n",
        "```\n",
        "\n",
        "3. The split between `train_data` and `test_data` in this problem enables you to do what kind of learning?\n",
        "\n",
        "```\n",
        "    a) Supervised learning\n",
        "    b) Unsupervised learning\n",
        "    c) Reinforcement learning\n",
        "    d) Representation learning\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b347724",
      "metadata": {},
      "source": [
        "### Exercise 2.2: Code interpretation (GRADED)\n",
        "Write a comment using `# <WRITE A COMMENT>` at the end of each line. Hint: Check the documentation for [`Dataframe.fillna()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna) and [`Dataframe.drop()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html#pandas.DataFrame.drop)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3b181f12",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\bahas\\AppData\\Local\\Temp\\ipykernel_38776\\3997862153.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  train_data = train_data.fillna(method='ffill')\n",
            "C:\\Users\\bahas\\AppData\\Local\\Temp\\ipykernel_38776\\3997862153.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  test_data = test_data.fillna(method='ffill')\n"
          ]
        }
      ],
      "source": [
        "# NaN stands for \"Not a Number\" and is a common way to represent missing data\n",
        "# What if our machine learning algorithm doesn't know how to handle missing data?\n",
        "print(train_data.isna().sum())\n",
        "train_data = train_data.fillna(method='ffill')\n",
        "test_data = test_data.fillna(method='ffill')\n",
        "\n",
        "# Some variables aren't useful for prediction, or aren't easy to use\n",
        "train_data = train_data.drop(['Name', 'Ticket', 'Cabin'], axis=1, errors='ignore')\n",
        "test_data = test_data.drop(['Name', 'Ticket', 'Cabin'], axis=1, errors='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15ccbb3e",
      "metadata": {
        "id": "15ccbb3e",
        "papermill": {
          "duration": 0.013487,
          "end_time": "2023-11-14T08:40:13.790535",
          "exception": false,
          "start_time": "2023-11-14T08:40:13.777048",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Decision Trees (pt 1): Data to test the algorithm\n",
        "In class, we talked about decision trees. The pseudocode given (from the textbook AIMA 19.3) was as follows:\n",
        "\n",
        "**function** LEARN-DECISION-TREE(*examples*, _attributes_, _parent\\_examples_) **returns** a tree<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;**if** _examples_ is empty **then return** PLURALITY-VALUE(_parent\\_examples_)<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;**else if** all _examples_ have the same classification **then return** the classification<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;**else if** _attributes_ is empty **then return** PLURALITY-VALUE(_examples_)<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;**else**<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;_A_ = argmax(IMPORTANCE(_a_, _examples_))<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;_tree_ = a new decision tree with root test _A_<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**for each** value _v_ of _A_ **do**<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;_exs_ = {_e_ : _e_ in _examples_ **and** _e.A_ = _v_}<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;_subtree_ = LEARN-DECISION-TREE(_exs_, _attributes_ - _A_, _examples_)<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;add a branch to _tree_ with label (_A_ = _v_) and subtree _subtree_<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**return** _tree_\n",
        "\n",
        "\n",
        "You will write this function in Python!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "90053d8e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Information Gain is the standard \"Importance\" for Decision Trees\n",
        "# Take these for granted for now\n",
        "def information_gain(attribute, examples):\n",
        "    return entropy(examples) - remainder(attribute, examples)\n",
        "\n",
        "def entropy(examples):\n",
        "    num_survived = len(examples[examples['Survived'] == 1])\n",
        "    num_died = len(examples[examples['Survived'] == 0])\n",
        "    total = len(examples)\n",
        "    if num_survived == 0 or num_died == 0:\n",
        "        return 0\n",
        "    p_survived = num_survived / total\n",
        "    p_died = num_died / total\n",
        "    return -p_survived * np.log2(p_survived) - p_died * np.log2(p_died)\n",
        "\n",
        "def remainder(attribute, examples):\n",
        "    total = len(examples)\n",
        "    remainder = 0\n",
        "    for value in examples[attribute].unique():\n",
        "        exs = examples[examples[attribute] == value]\n",
        "        remainder += len(exs) / total * entropy(exs)\n",
        "    return remainder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a90472b3",
      "metadata": {},
      "source": [
        "## Exercise 2.3: Decision tree implementation (GRADED)\n",
        "Turn the pseudocode for LEARN-DECISION-TREE into a real Python function, calling the `information_gain()` function defined above.\n",
        "\n",
        "You also need to define `plurality_value()`, which should return a `0` if there are more 0s left in the `examples`, or a `1` if more 1s are left in the `examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "f55ef8ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plurality_value(examples):    \n",
        "# <YOUR CODE HERE>\n",
        "    return 0 # Placeholder\n",
        "\n",
        "def learn_decision_tree(examples, attributes, parent_examples):\n",
        "# <YOUR CODE HERE>\n",
        "    return {\"no attribute\" : {}} # Placeholder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50e84641",
      "metadata": {},
      "source": [
        "Now, let's test our code. At any given place in the tree (node), one of these 4 cases applies:\n",
        "\n",
        "1. Examples at this node are all 1 (survivors) or all 0 (non-survivors).\n",
        "2. Examples at this node are mixed between 1 and 0.\n",
        "3. There are no examples at this node.\n",
        "4. There are no attributes at this node.\n",
        "\n",
        "Below, let's mimic each of the 4 cases of data. There are 4 \"mini\" data sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4be56d62",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A\n",
            "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
            "1            2         1       1  female  38.0      1      0  71.2833        C\n",
            "2            3         1       3  female  26.0      0      0   7.9250        S\n",
            "3            4         1       1  female  35.0      1      0  53.1000        S\n",
            "8            9         1       3  female  27.0      0      2  11.1333        S\n",
            "9           10         1       2  female  14.0      1      0  30.0708        C\n",
            "B\n",
            "   PassengerId  Survived  Pclass   Sex   Age  SibSp  Parch     Fare Embarked\n",
            "6            7         0       1  male  54.0      0      0  51.8625        S\n",
            "C\n",
            "Empty DataFrame\n",
            "Columns: [PassengerId, Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "mini_data = train_data.head(10)\n",
        "\n",
        "# Option A\n",
        "parent_examples_A = mini_data[mini_data['Sex'] == 'female']\n",
        "examples_A = mini_data[\n",
        "    ((mini_data['Sex'] == 'female') & mini_data['Survived'] == 1)]\n",
        "\n",
        "# Option B\n",
        "examples_B = mini_data[mini_data['Age'] > 40]\n",
        "\n",
        "# Option C\n",
        "examples_C = mini_data[mini_data['Age'] > 90]\n",
        "\n",
        "print(\"A\")\n",
        "print(examples_A)\n",
        "print(\"B\")\n",
        "print(examples_B)\n",
        "print(\"C\")\n",
        "print(examples_C)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "630558cc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'PassengerId': {np.int64(1): np.int64(0), np.int64(2): np.int64(1), np.int64(3): np.int64(1), np.int64(4): np.int64(1), np.int64(5): np.int64(0), np.int64(6): np.int64(0), np.int64(7): np.int64(0), np.int64(8): np.int64(0), np.int64(9): np.int64(1), np.int64(10): np.int64(1), np.int64(11): np.int64(1), np.int64(12): np.int64(1), np.int64(13): np.int64(0), np.int64(14): np.int64(0), np.int64(15): np.int64(0), np.int64(16): np.int64(1), np.int64(17): np.int64(0), np.int64(18): np.int64(1), np.int64(19): np.int64(0), np.int64(20): np.int64(1), np.int64(21): np.int64(0), np.int64(22): np.int64(1), np.int64(23): np.int64(1), np.int64(24): np.int64(1), np.int64(25): np.int64(0), np.int64(26): np.int64(1), np.int64(27): np.int64(0), np.int64(28): np.int64(0), np.int64(29): np.int64(1), np.int64(30): np.int64(0)}}\n"
          ]
        }
      ],
      "source": [
        "output = learn_decision_tree(mini_data, mini_data.columns[:-1], None)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c536dc0",
      "metadata": {
        "id": "3c536dc0",
        "papermill": {
          "duration": 0.013158,
          "end_time": "2023-11-14T08:40:14.035590",
          "exception": false,
          "start_time": "2023-11-14T08:40:14.022432",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# FOR LATER (12 Mar 2025)\n",
        "## Data Splitting\n",
        "In the meantime, we'll split the training dataset again, into a training and development/validation set. (Remember that we need a validation set so that we can set _hyperparameters_ before running an algorithm on the test data.)\n",
        "\n",
        "We'll use the classic ML library `sklearn` for a utility to help us do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbd3e722",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "execution": {
          "iopub.execute_input": "2023-11-14T08:40:14.066756Z",
          "iopub.status.busy": "2023-11-14T08:40:14.066305Z",
          "iopub.status.idle": "2023-11-14T08:40:14.442019Z",
          "shell.execute_reply": "2023-11-14T08:40:14.440728Z"
        },
        "id": "cbd3e722",
        "outputId": "afddaa9e-8605-409b-a6b4-c490d22d07f2",
        "papermill": {
          "duration": 0.394005,
          "end_time": "2023-11-14T08:40:14.444607",
          "exception": false,
          "start_time": "2023-11-14T08:40:14.050602",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "# Get indices for a split\n",
        "split = ShuffleSplit(n_splits = 1, test_size = 0.2)\n",
        "# Iterate through (only 1) split, setting train/val data\n",
        "for train_indices, test_indicices in split.split(train_data):\n",
        "    train_set = train_data.loc[train_indices]\n",
        "    val_set = train_data.loc[test_indicices]\n",
        "\n",
        "display(train_set['Pclass'].value_counts() / train_set.shape[0] * 100)\n",
        "display(val_set['Pclass'].value_counts() / val_set.shape[0] * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "424f6d56",
      "metadata": {
        "id": "424f6d56",
        "papermill": {
          "duration": 0.015597,
          "end_time": "2023-11-14T08:40:14.475239",
          "exception": false,
          "start_time": "2023-11-14T08:40:14.459642",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Assignment 2a: Stratified sampling\n",
        "If, for example, your training data is 70% men and 30% women, but your test data is 80% women and 20% men, your ML model may not perform well on the test. This is called _sampling bias_. To help with this problem, we can try _stratifying_ the data according to variables of interest (e.g., `Sex`). This ensures both training and validation have similar distributions of the 'Survived', 'Pclass', and 'Sex' features for unbiased model evaluation.\n",
        "\n",
        "* Write an alternative split, stratifying the split according to 'Survived', 'PClass', and 'Sex'. Save the output as `strat_train_set` and `strat_val_set`. (Hint: pass in the columns you want to stratify via `y` in `StratifiedShuffleSplit`'s [`split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html#sklearn.model_selection.StratifiedShuffleSplit.split).)\n",
        "* Verify that the percent of samples in each 'Pclass' value and `Sex` value are the same in `strat_train_set` and `strat_val_set`. (Hint: use Dataframe's `value_counts()` method.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cffe6269",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "execution": {
          "iopub.execute_input": "2023-11-14T08:40:14.506824Z",
          "iopub.status.busy": "2023-11-14T08:40:14.506266Z",
          "iopub.status.idle": "2023-11-14T08:40:14.541498Z",
          "shell.execute_reply": "2023-11-14T08:40:14.539961Z"
        },
        "id": "cffe6269",
        "outputId": "51ddf91f-23b3-4a43-bcc2-28c4ec924502",
        "papermill": {
          "duration": 0.055031,
          "end_time": "2023-11-14T08:40:14.544361",
          "exception": false,
          "start_time": "2023-11-14T08:40:14.489330",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# <YOUR CODE HERE>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1028d425",
      "metadata": {
        "id": "1028d425",
        "papermill": {
          "duration": 0.014607,
          "end_time": "2023-11-14T08:40:14.575175",
          "exception": false,
          "start_time": "2023-11-14T08:40:14.560568",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Establishing a baseline\n",
        "Besides splitting the data, we need a few more steps of data preparation before our machine learning algorithm can work.\n",
        "\n",
        "1. We can get rid of columns that are unlikely to contribute to the predictions: see `.drop()` below.\n",
        "2. We need to transform string data into categorical/numerical values (for the way some machine learning algorithms are optimized): see `pd.get_dummies()` below.\n",
        "\n",
        "How to do this more reliably is another issue; for now, here are quick and dirty ways to do these.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b57cafc1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "execution": {
          "iopub.execute_input": "2023-11-14T08:40:14.606362Z",
          "iopub.status.busy": "2023-11-14T08:40:14.605912Z",
          "iopub.status.idle": "2023-11-14T08:40:14.636597Z",
          "shell.execute_reply": "2023-11-14T08:40:14.635182Z"
        },
        "id": "b57cafc1",
        "outputId": "268e5d0c-9187-46e7-d099-2282ad46eb35",
        "papermill": {
          "duration": 0.049488,
          "end_time": "2023-11-14T08:40:14.639412",
          "exception": false,
          "start_time": "2023-11-14T08:40:14.589924",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "X_train = pd.get_dummies(train_set.drop([\"Survived\"], axis=1))\n",
        "y_train = train_set[\"Survived\"]\n",
        "\n",
        "X_val = pd.get_dummies(val_set.drop([\"Survived\"], axis=1))\n",
        "y_val = val_set[\"Survived\"]\n",
        "\n",
        "display(X_train.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "548feccb",
      "metadata": {
        "id": "548feccb",
        "papermill": {
          "duration": 0.015102,
          "end_time": "2023-11-14T08:40:14.669251",
          "exception": false,
          "start_time": "2023-11-14T08:40:14.654149",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "We'll use a Random Forest with some pre-chosen settings as our baseline to classify between `Survived=0` and `Survived=1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ee3172b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-14T08:40:14.769855Z",
          "iopub.status.busy": "2023-11-14T08:40:14.769247Z",
          "iopub.status.idle": "2023-11-14T08:40:15.518440Z",
          "shell.execute_reply": "2023-11-14T08:40:15.516960Z"
        },
        "id": "7ee3172b",
        "outputId": "17647483-c95c-4925-9821-0b3e926fa714",
        "papermill": {
          "duration": 0.767894,
          "end_time": "2023-11-14T08:40:15.521143",
          "exception": false,
          "start_time": "2023-11-14T08:40:14.753249",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(\n",
        "    n_estimators=100, max_depth=5, random_state=1)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "acc = clf.score(X_val, y_val)\n",
        "\n",
        "print(f\"Your {clf.__class__.__name__} predicts 'Survived'\")\n",
        "print(f\" with an validation set accuracy of {acc*100:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce826cd8",
      "metadata": {
        "id": "ce826cd8",
        "papermill": {
          "duration": 0.014683,
          "end_time": "2023-11-14T08:40:15.551095",
          "exception": false,
          "start_time": "2023-11-14T08:40:15.536412",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Congratulations! You've trained and run your first ML algorithm!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30fd1f0f",
      "metadata": {
        "id": "30fd1f0f",
        "papermill": {
          "duration": 0.014187,
          "end_time": "2023-11-14T08:40:15.579873",
          "exception": false,
          "start_time": "2023-11-14T08:40:15.565686",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Assignment 2b: Evaluation practice\n",
        "Now that we have a working ML classifier, let's look at the evaluation environment.\n",
        "\n",
        "* ML algorithms often give different answers even with the same parameters. Write a loop that trains the same type of classifier 5 times and averages the scores. (Hint: vary or remove `random_state`.)\n",
        "* ML algorithms have lots of options. Today, we're not focusing on what those options mean, but on how to test between them. Write a loop or other function that tests out the hyperparameters (options) for [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier): `n_estimators` and `max_depth`. Which values for each option give the best (averaged over 5) results?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f96d7748",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-14T08:40:15.612639Z",
          "iopub.status.busy": "2023-11-14T08:40:15.612225Z",
          "iopub.status.idle": "2023-11-14T08:40:20.029628Z",
          "shell.execute_reply": "2023-11-14T08:40:20.027831Z"
        },
        "id": "f96d7748",
        "papermill": {
          "duration": 4.437299,
          "end_time": "2023-11-14T08:40:20.032618",
          "exception": false,
          "start_time": "2023-11-14T08:40:15.595319",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# <YOUR CODE HERE>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d292dc38",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-14T08:40:20.065103Z",
          "iopub.status.busy": "2023-11-14T08:40:20.064606Z",
          "iopub.status.idle": "2023-11-14T08:40:20.074494Z",
          "shell.execute_reply": "2023-11-14T08:40:20.073062Z"
        },
        "id": "d292dc38",
        "papermill": {
          "duration": 0.029989,
          "end_time": "2023-11-14T08:40:20.077446",
          "exception": false,
          "start_time": "2023-11-14T08:40:20.047457",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "average_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80742d10",
      "metadata": {
        "id": "80742d10",
        "papermill": {
          "duration": 0.014505,
          "end_time": "2023-11-14T08:40:20.107678",
          "exception": false,
          "start_time": "2023-11-14T08:40:20.093173",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Extra: Cross-validation\n",
        "Cross-validation on a training set can be very helpful for finding the best values. In `sklearn` you can do this with less code.\n",
        "\n",
        "Use [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) and/or [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV) to find the best values for hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b425ded",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-14T08:40:20.139620Z",
          "iopub.status.busy": "2023-11-14T08:40:20.139206Z",
          "iopub.status.idle": "2023-11-14T08:41:08.618206Z",
          "shell.execute_reply": "2023-11-14T08:41:08.617158Z"
        },
        "id": "1b425ded",
        "papermill": {
          "duration": 48.514994,
          "end_time": "2023-11-14T08:41:08.637594",
          "exception": false,
          "start_time": "2023-11-14T08:40:20.122600",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# <YOUR CODE HERE>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36259254",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-14T08:41:08.670741Z",
          "iopub.status.busy": "2023-11-14T08:41:08.670043Z",
          "iopub.status.idle": "2023-11-14T08:41:08.691390Z",
          "shell.execute_reply": "2023-11-14T08:41:08.689203Z"
        },
        "id": "36259254",
        "papermill": {
          "duration": 0.042274,
          "end_time": "2023-11-14T08:41:08.694711",
          "exception": false,
          "start_time": "2023-11-14T08:41:08.652437",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "final_clf = grid_search.best_estimator_\n",
        "final_clf.score(X_val,y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e614bae",
      "metadata": {
        "id": "3e614bae",
        "papermill": {
          "duration": 0.014682,
          "end_time": "2023-11-14T08:41:08.724897",
          "exception": false,
          "start_time": "2023-11-14T08:41:08.710215",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Extra: Held-out data evaluation on Kaggle\n",
        "The Titanic data can actually be tested further on held-out data, which does not have gold standard labels (`Survived` = 0 or 1). To do this:\n",
        "\n",
        "* Download this Jupyter notebook\n",
        "* Sign up for [kaggle.com](https://www.kaggle.com)\n",
        "* Visit the page for the [Titanic competition](https://www.kaggle.com/competitions/titanic), from which we borrowed this data and problem setting, and sign up to participate\n",
        "* Upload this Jupyter notebook (Note: Kaggle has a native Jupyter notebook editor that's very similar to Google Colab)\n",
        "* Change the input files to point to local competition files (i.e., `\"/kaggle/input/titanic/train.csv\"` and `\"/kaggle/input/titanic/test.csv\"`)\n",
        "* Create the output file `submission.csv` below, and then click \"Submit\" to _run all the cells in the Notebook_, _re-create_ `submission.csv`, and submit that for scoring on the Competition's leaderboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b922b2c6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-14T08:41:08.757599Z",
          "iopub.status.busy": "2023-11-14T08:41:08.756910Z",
          "iopub.status.idle": "2023-11-14T08:41:08.788129Z",
          "shell.execute_reply": "2023-11-14T08:41:08.786634Z"
        },
        "id": "b922b2c6",
        "papermill": {
          "duration": 0.051217,
          "end_time": "2023-11-14T08:41:08.791115",
          "exception": false,
          "start_time": "2023-11-14T08:41:08.739898",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = clf # use the baseline Random Forest or replace with Assignment 3\n",
        "X_test = pd.get_dummies(test_data) # clean the test data in the same way as train\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
        "output.to_csv('submission.csv', index=False)\n",
        "print(\"Your submission was successfully saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23a45105",
      "metadata": {
        "id": "23a45105",
        "papermill": {
          "duration": 0.016129,
          "end_time": "2023-11-14T08:41:08.822730",
          "exception": false,
          "start_time": "2023-11-14T08:41:08.806601",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Now click on the 3 vertical dots for options,  to your Kaggle page and go to `Submit to competition` and click on `Submit`.\n",
        "\n",
        "You've finished your first Kaggle submission! Check your `Score`, and then keep on learning how to code AI!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xe5SQqbskXtq",
      "metadata": {
        "id": "xe5SQqbskXtq"
      },
      "source": [
        "# Solutions\n",
        "The solutions for this notebook can be found [here](https://colab.research.google.com/drive/13mV9dGzf4HIQh97zt6uFZOx5crDt1J1P?usp=sharing)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 65.391415,
      "end_time": "2023-11-14T08:41:09.560267",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-11-14T08:40:04.168852",
      "version": "2.4.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
